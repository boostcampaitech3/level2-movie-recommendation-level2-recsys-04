{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.cluster import (\n",
    "    completeness_score,\n",
    "    homogeneity_score,\n",
    "    v_measure_score,\n",
    ")\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.transforms import RandomLinkSplit, ToUndirected\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "import torch.nn.functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001b[1muser\u001b[0m={ num_nodes=31360 },\n",
      "  \u001b[1mmovie\u001b[0m={ num_nodes=6807 },\n",
      "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
      "    edge_index=[2, 5154471],\n",
      "    edge_label=[5154471, 1]\n",
      "  }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1muser\u001b[0m={ x=[31360, 1] },\n",
      "  \u001b[1mmovie\u001b[0m={ x=[6807, 1] },\n",
      "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
      "    edge_index=[2, 5154471],\n",
      "    edge_label=[5154471, 1]\n",
      "  },\n",
      "  \u001b[1m(movie, rev_rates, user)\u001b[0m={ edge_index=[2, 5154471] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def load_node_csv(path, index_col, item_col, encoders=None, **kwargs):\n",
    "    df = pd.read_csv(path, **kwargs)\n",
    "    mapping = {index: i for i, index in enumerate(df[index_col].unique())}\n",
    "\n",
    "    x = np.arange(df[item_col].nunique()).reshape(-1,1)\n",
    "    \n",
    "    if encoders is not None:\n",
    "        x = None\n",
    "        xs = [encoder(df[col]) for col, encoder in encoders.items()]\n",
    "        x = torch.cat(xs, dim=-1)\n",
    "\n",
    "    return x, mapping\n",
    "\n",
    "\n",
    "def load_edge_csv(path, src_index_col, src_mapping, dst_index_col, dst_mapping,\n",
    "                  encoders=None, **kwargs):\n",
    "    df = pd.read_csv(path, **kwargs)\n",
    "\n",
    "    src = [src_mapping[index] for index in df[src_index_col]]\n",
    "    dst = [dst_mapping[index] for index in df[dst_index_col]]\n",
    "    edge_index = torch.tensor([src, dst])\n",
    "\n",
    "    edge_attr = None\n",
    "    if encoders is not None:\n",
    "        edge_attrs = [encoder(df[col]) for col, encoder in encoders.items()]\n",
    "        edge_attr = torch.cat(edge_attrs, dim=-1)\n",
    "\n",
    "    return edge_index, edge_attr\n",
    "\n",
    "\n",
    "class IdentityEncoder(object):\n",
    "    # The 'IdentityEncoder' takes the raw column values and converts them to\n",
    "    # PyTorch tensors.\n",
    "    def __init__(self, dtype=None):\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def __call__(self, df):\n",
    "        return torch.from_numpy(np.ones_like(df.values)).view(-1, 1).to(self.dtype)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "rating_path = '/opt/ml/input/data/train/train_ratings.csv'\n",
    "\n",
    "movie_x, user_mapping = load_node_csv(rating_path, index_col='user', item_col='item')\n",
    "\n",
    "df = pd.read_csv(rating_path)\n",
    "movie_mapping = {index: i for i, index in enumerate(df.item.unique())}\n",
    "edge_index, edge_label = load_edge_csv(\n",
    "    rating_path,\n",
    "    src_index_col='user',\n",
    "    src_mapping=user_mapping,\n",
    "    dst_index_col='item',\n",
    "    dst_mapping=movie_mapping,\n",
    "    encoders={'item': IdentityEncoder(dtype=torch.long)},\n",
    ")\n",
    "\n",
    "data = HeteroData()\n",
    "\n",
    "data['user'].num_nodes = len(user_mapping)  # Users do not have any features.\n",
    "data['movie'].num_nodes = len(movie_mapping)\n",
    "data['user', 'rates', 'movie'].edge_index = edge_index\n",
    "data['user', 'rates', 'movie'].edge_label = edge_label\n",
    "\n",
    "# data = data.pin_memory()\n",
    "# data = data.to('cuda:0', non_blocking=True)\n",
    "\n",
    "print(data)\n",
    "data['user'].x = torch.ones(data['user'].num_nodes, 1, dtype=torch.float32)\n",
    "del data['user'].num_nodes\n",
    "\n",
    "data['movie'].x = torch.ones(data['movie'].num_nodes, 1, dtype=torch.float32)\n",
    "del data['movie'].num_nodes\n",
    "\n",
    "data = data.to(device)\n",
    "# We can now convert `data` into an appropriate format for training a\n",
    "# graph-based machine learning model:\n",
    "\n",
    "# 1. Add a reverse ('movie', 'rev_rates', 'user') relation for message passing.\n",
    "data = ToUndirected()(data)\n",
    "del data['movie', 'rev_rates', 'user'].edge_label  # Remove \"reverse\" label.\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = InMemoryDataset.collate([data])[0].to(device)\n",
    "# data = data.to_homogeneous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1muser\u001b[0m={ x=[31360, 1] },\n",
       "  \u001b[1mmovie\u001b[0m={ x=[6807, 1] },\n",
       "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
       "    edge_index=[2, 5154471],\n",
       "    edge_label=[5154471, 1]\n",
       "  },\n",
       "  \u001b[1m(movie, rev_rates, user)\u001b[0m={ edge_index=[2, 5154471] }\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    neg_sampling_ratio=0.0,\n",
    "    edge_types=[('user', 'rates', 'movie')],\n",
    "    rev_edge_types=[('movie', 'rev_rates', 'user')],\n",
    ")(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001b[1muser\u001b[0m={ x=[31360, 1] },\n",
      "  \u001b[1mmovie\u001b[0m={ x=[6807, 1] },\n",
      "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
      "    edge_index=[2, 5154471],\n",
      "    edge_label=[5154471, 1]\n",
      "  },\n",
      "  \u001b[1m(movie, rev_rates, user)\u001b[0m={ edge_index=[2, 5154471] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1muser\u001b[0m={ x=[31360, 1] },\n",
      "  \u001b[1mmovie\u001b[0m={ x=[6807, 1] },\n",
      "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
      "    edge_index=[2, 4123577],\n",
      "    edge_label=[4123577, 1],\n",
      "    edge_label_index=[2, 4123577]\n",
      "  },\n",
      "  \u001b[1m(movie, rev_rates, user)\u001b[0m={ edge_index=[2, 4123577] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[30479, 19339, 15912,  ..., 20114, 28161, 11963],\n",
       "        [ 1280,  3804,   301,  ...,  3822,   922,  2516]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[('user', 'rates', 'movie')].edge_label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32)\n",
    "test_loader = DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = nn.Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z)\n",
    "        return z.view(-1)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        z = self.encoder(x, edge_index)\n",
    "        return self.decoder(z)\n",
    "\n",
    "\n",
    "model = Model(hidden_channels=32).to(device)\n",
    "\n",
    "# # Due to lazy initialization, we need to run one model step so the number\n",
    "# # of parameters can be inferred:\n",
    "# with torch.no_grad():\n",
    "#     model.encoder(train_data.x_dict, train_data.edge_index_dict)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(data.x, data.edge_index)\n",
    "        target = data.edge_label.float()\n",
    "        loss = F.binary_cross_entropy_with_logits(pred, target).sqrt()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "    return total_loss / len(train_data)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(dataloader):\n",
    "    model.eval()\n",
    "    total_rmse = 0\n",
    "    for data in dataloader:\n",
    "        pred = model(data.x, data.edge_index)\n",
    "        pred = pred.clamp(min=0, max=1)\n",
    "        target = data.edge_label.float()\n",
    "        rmse = F.binary_cross_entropy_with_logits(pred, target).sqrt()\n",
    "        total_rmse += rmse\n",
    "    return float(total_rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 11):\n",
    "    loss = train()\n",
    "    train_rmse = test(train_data)\n",
    "    val_rmse = test(val_data)\n",
    "    test_rmse = test(test_data)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n",
    "          f'Val: {val_rmse:.4f}, Test: {test_rmse:.4f}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
