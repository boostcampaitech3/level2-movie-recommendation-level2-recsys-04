{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, Tensor\n",
    "\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "\n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.typing import Adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "rating_path = '/opt/ml/input/data/train/train_ratings.csv'\n",
    "df = pd.read_csv(rating_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user      31360\n",
       "item       6807\n",
       "time    5074973\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164.36450892857144"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('user')['item'].size().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapping = {index: i for i, index in enumerate(df.user.unique())}\n",
    "item_mapping = {index: i for i, index in enumerate(df.item.unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_mapping[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     0,  ..., 31359, 31359, 31359],\n",
       "        [    0,     1,     2,  ...,   331,   733,  2256]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_edge_csv(df, src_index_col, src_mapping, dst_index_col, dst_mapping):\n",
    "    \"\"\"Loads csv containing edges between users and items\n",
    "\n",
    "    Args:\n",
    "        df (pandas DataFrame): pandas DataFrame of user-item interaactions\n",
    "        src_index_col (str): column name of users\n",
    "        src_mapping (dict): mapping between row number and user id\n",
    "        dst_index_col (str): column name of items\n",
    "        dst_mapping (dict): mapping between row number and item id\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: 2 by N matrix containing the node ids of N user-item edges\n",
    "    \"\"\"\n",
    "    src = [src_mapping[index] for index in df[src_index_col]]\n",
    "    dst = [dst_mapping[index] for index in df[dst_index_col]]\n",
    "\n",
    "    return torch.tensor([src, dst])\n",
    "\n",
    "\n",
    "edge_index = load_edge_csv(\n",
    "    df,\n",
    "    src_index_col='user',\n",
    "    src_mapping=user_mapping,\n",
    "    dst_index_col='item',\n",
    "    dst_mapping=item_mapping\n",
    ")\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users, num_movies = len(user_mapping), len(item_mapping)\n",
    "num_interactions = edge_index.shape[1]\n",
    "\n",
    "all_indices = np.arange(num_interactions)\n",
    "train_indices, test_indices = train_test_split(\n",
    "    all_indices, test_size=0.2, random_state=1)\n",
    "val_indices, test_indices = train_test_split(\n",
    "    test_indices, test_size=0.5, random_state=1)\n",
    "\n",
    "train_edge_index = edge_index[:, train_indices]\n",
    "val_edge_index = edge_index[:, val_indices]\n",
    "test_edge_index = edge_index[:, test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert edge indices into Sparse Tensors: https://pytorch-geometric.readthedocs.io/en/latest/notes/sparse_tensor.html\n",
    "train_sparse_edge_index = SparseTensor(row=train_edge_index[0], col=train_edge_index[1], sparse_sizes=(\n",
    "    num_users + num_movies, num_users + num_movies))\n",
    "val_sparse_edge_index = SparseTensor(row=val_edge_index[0], col=val_edge_index[1], sparse_sizes=(\n",
    "    num_users + num_movies, num_users + num_movies))\n",
    "test_sparse_edge_index = SparseTensor(row=test_edge_index[0], col=test_edge_index[1], sparse_sizes=(\n",
    "    num_users + num_movies, num_users + num_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function which random samples a mini-batch of positive and negative samples\n",
    "def sample_mini_batch(batch_size, edge_index):\n",
    "    \"\"\"Randomly samples indices of a minibatch given an adjacency matrix\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): minibatch size\n",
    "        edge_index (torch.Tensor): 2 by N list of edges\n",
    "\n",
    "    Returns:\n",
    "        tuple: user indices, positive item indices, negative item indices\n",
    "    \"\"\"\n",
    "    edges = structured_negative_sampling(edge_index, num_nodes=6807) ###### dirty code.... #######\n",
    "    edges = torch.stack(edges, dim=0)\n",
    "    indices = random.choices(\n",
    "        [i for i in range(edges[0].shape[0])], k=batch_size)\n",
    "    batch = edges[:, indices]\n",
    "    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
    "    return user_indices, pos_item_indices, neg_item_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines LightGCN model\n",
    "class LightGCN(MessagePassing):\n",
    "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64, K=3, add_self_loops=False):\n",
    "        \"\"\"Initializes LightGCN Model\n",
    "\n",
    "        Args:\n",
    "            num_users (int): Number of users\n",
    "            num_items (int): Number of items\n",
    "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
    "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
    "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_users, self.num_items = num_users, num_items\n",
    "        self.embedding_dim, self.K = embedding_dim, K\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        self.users_emb = nn.Embedding(\n",
    "            num_embeddings=self.num_users, embedding_dim=self.embedding_dim) # e_u^0\n",
    "        self.items_emb = nn.Embedding(\n",
    "            num_embeddings=self.num_items, embedding_dim=self.embedding_dim) # e_i^0\n",
    "\n",
    "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
    "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
    "\n",
    "    def forward(self, edge_index: SparseTensor):\n",
    "        \"\"\"Forward propagation of LightGCN Model.\n",
    "\n",
    "        Args:\n",
    "            edge_index (SparseTensor): adjacency matrix\n",
    "\n",
    "        Returns:\n",
    "            tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n",
    "        \"\"\"\n",
    "        # compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
    "        edge_index_norm = gcn_norm(\n",
    "            edge_index, add_self_loops=self.add_self_loops)\n",
    "\n",
    "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n",
    "        embs = [emb_0]\n",
    "        emb_k = emb_0\n",
    "\n",
    "        # multi-scale diffusion\n",
    "        for i in range(self.K):\n",
    "            emb_k = self.propagate(edge_index_norm, x=emb_k)\n",
    "            embs.append(emb_k)\n",
    "\n",
    "        embs = torch.stack(embs, dim=1)\n",
    "        emb_final = torch.mean(embs, dim=1) # E^K\n",
    "\n",
    "        users_emb_final, items_emb_final = torch.split(\n",
    "            emb_final, [self.num_users, self.num_items]) # splits into e_u^K and e_i^K\n",
    "\n",
    "        # returns e_u^K, e_u^0, e_i^K, e_i^0\n",
    "        # print(users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight)\n",
    "        return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
    "\n",
    "    def message(self, x_j: Tensor) -> Tensor:\n",
    "        return x_j\n",
    "\n",
    "    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
    "        # computes \\tilde{A} @ x\n",
    "        return matmul(adj_t, x)\n",
    "\n",
    "model = LightGCN(num_users, num_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, lambda_val):\n",
    "    \"\"\"Bayesian Personalized Ranking Loss as described in https://arxiv.org/abs/1205.2618\n",
    "\n",
    "    Args:\n",
    "        users_emb_final (torch.Tensor): e_u_k\n",
    "        users_emb_0 (torch.Tensor): e_u_0\n",
    "        pos_items_emb_final (torch.Tensor): positive e_i_k\n",
    "        pos_items_emb_0 (torch.Tensor): positive e_i_0\n",
    "        neg_items_emb_final (torch.Tensor): negative e_i_k\n",
    "        neg_items_emb_0 (torch.Tensor): negative e_i_0\n",
    "        lambda_val (float): lambda value for regularization loss term\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: scalar bpr loss value\n",
    "    \"\"\"\n",
    "    reg_loss = lambda_val * (users_emb_0.norm(2).pow(2) +\n",
    "                             pos_items_emb_0.norm(2).pow(2) +\n",
    "                             neg_items_emb_0.norm(2).pow(2)) # L2 loss\n",
    "\n",
    "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
    "    pos_scores = torch.sum(pos_scores, dim=-1) # predicted scores of positive samples\n",
    "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
    "    neg_scores = torch.sum(neg_scores, dim=-1) # predicted scores of negative samples\n",
    "\n",
    "    loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores)) + reg_loss\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " # helper function to get N_u\n",
    "def get_user_positive_items(edge_index):\n",
    "    \"\"\"Generates dictionary of positive items for each user\n",
    "\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): 2 by N list of edges\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary of positive items for each user\n",
    "    \"\"\"\n",
    "    user_pos_items = {}\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        user = edge_index[0][i].item()\n",
    "        item = edge_index[1][i].item()\n",
    "        if user not in user_pos_items:\n",
    "            user_pos_items[user] = []\n",
    "        user_pos_items[user].append(item)\n",
    "    return user_pos_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes recall@K and precision@K\n",
    "def RecallPrecision_ATk(groundTruth, r, k):\n",
    "    \"\"\"Computers recall @ k and precision @ k\n",
    "\n",
    "    Args:\n",
    "        groundTruth (list): list of lists containing highly rated items of each user\n",
    "        r (list): list of lists indicating whether each top k item recommended to each user\n",
    "            is a top k ground truth item or not\n",
    "        k (intg): determines the top k items to compute precision and recall on\n",
    "\n",
    "    Returns:\n",
    "        tuple: recall @ k, precision @ k\n",
    "    \"\"\"\n",
    "    num_correct_pred = torch.sum(r, dim=-1)  # number of correctly predicted items per user\n",
    "    # number of items liked by each user in the test set\n",
    "    user_num_liked = torch.Tensor([len(groundTruth[i])\n",
    "                                  for i in range(len(groundTruth))])\n",
    "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
    "    precision = torch.mean(num_correct_pred) / k\n",
    "    return recall.item(), precision.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes NDCG@K\n",
    "def NDCGatK_r(groundTruth, r, k):\n",
    "    \"\"\"Computes Normalized Discounted Cumulative Gain (NDCG) @ k\n",
    "\n",
    "    Args:\n",
    "        groundTruth (list): list of lists containing highly rated items of each user\n",
    "        r (list): list of lists indicating whether each top k item recommended to each user\n",
    "            is a top k ground truth item or not\n",
    "        k (int): determines the top k items to compute ndcg on\n",
    "\n",
    "    Returns:\n",
    "        float: ndcg @ k\n",
    "    \"\"\"\n",
    "    assert len(r) == len(groundTruth)\n",
    "\n",
    "    test_matrix = torch.zeros((len(r), k))\n",
    "\n",
    "    for i, items in enumerate(groundTruth):\n",
    "        length = min(len(items), k)\n",
    "        test_matrix[i, :length] = 1\n",
    "    max_r = test_matrix\n",
    "    idcg = torch.sum(max_r * 1. / torch.log2(torch.arange(2, k + 2)), axis=1)\n",
    "    dcg = r * (1. / torch.log2(torch.arange(2, k + 2)))\n",
    "    dcg = torch.sum(dcg, axis=1)\n",
    "    idcg[idcg == 0.] = 1.\n",
    "    ndcg = dcg / idcg\n",
    "    ndcg[torch.isnan(ndcg)] = 0.\n",
    "    return torch.mean(ndcg).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function to get evaluation metrics\n",
    "def get_metrics(model, edge_index, exclude_edge_indices, k):\n",
    "    \"\"\"Computes the evaluation metrics: recall, precision, and ndcg @ k\n",
    "\n",
    "    Args:\n",
    "        model (LighGCN): lightgcn model\n",
    "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
    "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
    "        k (int): determines the top k items to compute metrics on\n",
    "\n",
    "    Returns:\n",
    "        tuple: recall @ k, precision @ k, ndcg @ k\n",
    "    \"\"\"\n",
    "    user_embedding = model.users_emb.weight\n",
    "    item_embedding = model.items_emb.weight\n",
    "\n",
    "    # get ratings between every user and item - shape is num users x num movies\n",
    "    rating = torch.matmul(user_embedding, item_embedding.T)\n",
    "\n",
    "    for exclude_edge_index in exclude_edge_indices:\n",
    "        # gets all the positive items for each user from the edge index\n",
    "        user_pos_items = get_user_positive_items(exclude_edge_index)\n",
    "        # get coordinates of all edges to exclude\n",
    "        exclude_users = []\n",
    "        exclude_items = []\n",
    "        for user, items in user_pos_items.items():\n",
    "            exclude_users.extend([user] * len(items))\n",
    "            exclude_items.extend(items)\n",
    "\n",
    "        # set ratings of excluded edges to large negative value\n",
    "        rating[exclude_users, exclude_items] = -(1 << 10)\n",
    "\n",
    "    # get the top k recommended items for each user\n",
    "    _, top_K_items = torch.topk(rating, k=k)\n",
    "\n",
    "    # get all unique users in evaluated split\n",
    "    users = edge_index[0].unique()\n",
    "\n",
    "    test_user_pos_items = get_user_positive_items(edge_index)\n",
    "\n",
    "    # convert test user pos items dictionary into a list\n",
    "    test_user_pos_items_list = [\n",
    "        test_user_pos_items[user.item()] for user in users]\n",
    "\n",
    "    # determine the correctness of topk predictions\n",
    "    r = []\n",
    "    for user in users:\n",
    "        ground_truth_items = test_user_pos_items[user.item()]\n",
    "        label = list(map(lambda x: x in ground_truth_items, top_K_items[user]))\n",
    "        r.append(label)\n",
    "    r = torch.Tensor(np.array(r).astype('float'))\n",
    "\n",
    "    recall, precision = RecallPrecision_ATk(test_user_pos_items_list, r, k)\n",
    "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
    "\n",
    "    return recall, precision, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function to evaluate model\n",
    "def evaluation(model, edge_index, sparse_edge_index, exclude_edge_indices, k, lambda_val):\n",
    "    \"\"\"Evaluates model loss and metrics including recall, precision, ndcg @ k\n",
    "\n",
    "    Args:\n",
    "        model (LighGCN): lightgcn model\n",
    "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
    "        sparse_edge_index (sparseTensor): sparse adjacency matrix for split to evaluate\n",
    "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
    "        k (int): determines the top k items to compute metrics on\n",
    "        lambda_val (float): determines lambda for bpr loss\n",
    "\n",
    "    Returns:\n",
    "        tuple: bpr loss, recall @ k, precision @ k, ndcg @ k\n",
    "    \"\"\"\n",
    "    # get embeddings\n",
    "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
    "        sparse_edge_index)\n",
    "    edges = structured_negative_sampling(\n",
    "        edge_index, num_nodes = 6807, contains_neg_self_loops=False)\n",
    "    user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n",
    "    # print(torch.max(user_indices), torch.max(pos_item_indices), torch.max(neg_item_indices)) #########\n",
    "    # print(user_indices, pos_item_indices, neg_item_indices) #############3\n",
    "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
    "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
    "        pos_item_indices], items_emb_0[pos_item_indices]\n",
    "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
    "        neg_item_indices], items_emb_0[neg_item_indices]\n",
    "\n",
    "    loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0,\n",
    "                    neg_items_emb_final, neg_items_emb_0, lambda_val).item()\n",
    "\n",
    "    recall, precision, ndcg = get_metrics(\n",
    "        model, edge_index, exclude_edge_indices, k)\n",
    "\n",
    "    return loss, recall, precision, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define contants\n",
    "ITERATIONS = 10000\n",
    "BATCH_SIZE = 1024\n",
    "LR = 1e-3\n",
    "ITERS_PER_EVAL = 200\n",
    "ITERS_PER_LR_DECAY = 200\n",
    "K = 20\n",
    "LAMBDA = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda.\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device {device}.\")\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "edge_index = edge_index.to(device)\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "train_sparse_edge_index = train_sparse_edge_index.to(device)\n",
    "\n",
    "val_edge_index = val_edge_index.to(device)\n",
    "val_sparse_edge_index = val_sparse_edge_index.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 0/10000] train_loss: -0.69096, val_loss: 0.29692, val_recall@20: 0.00311, val_precision@20: 0.00259, val_ndcg@20: 0.00321\n",
      "[Iteration 200/10000] train_loss: -1.00297, val_loss: 0.81064, val_recall@20: 0.04783, val_precision@20: 0.03676, val_ndcg@20: 0.04986\n",
      "[Iteration 400/10000] train_loss: -4.05538, val_loss: 2.93799, val_recall@20: 0.10275, val_precision@20: 0.0756, val_ndcg@20: 0.10699\n",
      "[Iteration 600/10000] train_loss: -8.3789, val_loss: 5.90447, val_recall@20: 0.11906, val_precision@20: 0.0838, val_ndcg@20: 0.12226\n",
      "[Iteration 800/10000] train_loss: -14.36145, val_loss: 9.53827, val_recall@20: 0.12413, val_precision@20: 0.0861, val_ndcg@20: 0.12699\n",
      "[Iteration 1000/10000] train_loss: -20.57232, val_loss: 13.69817, val_recall@20: 0.12534, val_precision@20: 0.08665, val_ndcg@20: 0.12972\n",
      "[Iteration 1200/10000] train_loss: -28.31191, val_loss: 18.16351, val_recall@20: 0.12639, val_precision@20: 0.08703, val_ndcg@20: 0.13098\n",
      "[Iteration 1400/10000] train_loss: -33.70828, val_loss: 22.87304, val_recall@20: 0.12723, val_precision@20: 0.08735, val_ndcg@20: 0.13168\n",
      "[Iteration 1600/10000] train_loss: -43.23748, val_loss: 27.81245, val_recall@20: 0.12756, val_precision@20: 0.08757, val_ndcg@20: 0.13232\n",
      "[Iteration 1800/10000] train_loss: -50.4336, val_loss: 32.83121, val_recall@20: 0.12762, val_precision@20: 0.08754, val_ndcg@20: 0.13244\n",
      "[Iteration 2000/10000] train_loss: -59.25236, val_loss: 37.86227, val_recall@20: 0.12787, val_precision@20: 0.08764, val_ndcg@20: 0.1328\n",
      "[Iteration 2200/10000] train_loss: -66.30063, val_loss: 42.95843, val_recall@20: 0.1281, val_precision@20: 0.08767, val_ndcg@20: 0.13277\n",
      "[Iteration 2400/10000] train_loss: -75.25103, val_loss: 48.00717, val_recall@20: 0.12828, val_precision@20: 0.08788, val_ndcg@20: 0.13308\n",
      "[Iteration 2600/10000] train_loss: -83.75107, val_loss: 52.92223, val_recall@20: 0.12848, val_precision@20: 0.08795, val_ndcg@20: 0.13305\n",
      "[Iteration 2800/10000] train_loss: -88.68216, val_loss: 57.65907, val_recall@20: 0.12862, val_precision@20: 0.08808, val_ndcg@20: 0.13343\n",
      "[Iteration 3000/10000] train_loss: -94.2718, val_loss: 62.55204, val_recall@20: 0.12846, val_precision@20: 0.08797, val_ndcg@20: 0.13344\n",
      "[Iteration 3200/10000] train_loss: -103.26505, val_loss: 66.96681, val_recall@20: 0.12876, val_precision@20: 0.08804, val_ndcg@20: 0.13338\n",
      "[Iteration 3400/10000] train_loss: -107.2222, val_loss: 71.40615, val_recall@20: 0.12879, val_precision@20: 0.0881, val_ndcg@20: 0.13333\n",
      "[Iteration 3600/10000] train_loss: -123.89343, val_loss: 75.58855, val_recall@20: 0.12905, val_precision@20: 0.08826, val_ndcg@20: 0.13369\n",
      "[Iteration 3800/10000] train_loss: -123.4202, val_loss: 79.89397, val_recall@20: 0.12894, val_precision@20: 0.08817, val_ndcg@20: 0.13366\n",
      "[Iteration 4000/10000] train_loss: -123.85194, val_loss: 84.13242, val_recall@20: 0.12882, val_precision@20: 0.08817, val_ndcg@20: 0.13366\n",
      "[Iteration 4200/10000] train_loss: -132.77127, val_loss: 87.99242, val_recall@20: 0.12879, val_precision@20: 0.08813, val_ndcg@20: 0.13355\n",
      "[Iteration 4400/10000] train_loss: -146.48471, val_loss: 91.57822, val_recall@20: 0.12886, val_precision@20: 0.08822, val_ndcg@20: 0.13347\n",
      "[Iteration 4600/10000] train_loss: -147.25284, val_loss: 95.06569, val_recall@20: 0.12875, val_precision@20: 0.08811, val_ndcg@20: 0.13338\n",
      "[Iteration 4800/10000] train_loss: -150.51106, val_loss: 98.52151, val_recall@20: 0.12884, val_precision@20: 0.08808, val_ndcg@20: 0.13342\n",
      "[Iteration 5000/10000] train_loss: -158.78491, val_loss: 101.97801, val_recall@20: 0.12879, val_precision@20: 0.08805, val_ndcg@20: 0.13338\n",
      "[Iteration 5200/10000] train_loss: -164.28644, val_loss: 104.98213, val_recall@20: 0.12899, val_precision@20: 0.08817, val_ndcg@20: 0.13353\n",
      "[Iteration 5400/10000] train_loss: -161.05327, val_loss: 108.28839, val_recall@20: 0.129, val_precision@20: 0.08819, val_ndcg@20: 0.13355\n",
      "[Iteration 5600/10000] train_loss: -165.18256, val_loss: 111.08217, val_recall@20: 0.12909, val_precision@20: 0.08821, val_ndcg@20: 0.13357\n",
      "[Iteration 5800/10000] train_loss: -178.61749, val_loss: 113.72006, val_recall@20: 0.12916, val_precision@20: 0.08825, val_ndcg@20: 0.13365\n",
      "[Iteration 6000/10000] train_loss: -181.92447, val_loss: 116.38504, val_recall@20: 0.12933, val_precision@20: 0.08833, val_ndcg@20: 0.13373\n",
      "[Iteration 6200/10000] train_loss: -183.78946, val_loss: 118.81422, val_recall@20: 0.12929, val_precision@20: 0.0883, val_ndcg@20: 0.13365\n",
      "[Iteration 6400/10000] train_loss: -188.93384, val_loss: 121.2085, val_recall@20: 0.12917, val_precision@20: 0.08825, val_ndcg@20: 0.13364\n",
      "[Iteration 6600/10000] train_loss: -199.59541, val_loss: 123.59361, val_recall@20: 0.12897, val_precision@20: 0.08815, val_ndcg@20: 0.13355\n",
      "[Iteration 6800/10000] train_loss: -191.96725, val_loss: 125.79893, val_recall@20: 0.1291, val_precision@20: 0.0882, val_ndcg@20: 0.1336\n",
      "[Iteration 7000/10000] train_loss: -198.828, val_loss: 127.95836, val_recall@20: 0.12912, val_precision@20: 0.08822, val_ndcg@20: 0.13362\n",
      "[Iteration 7200/10000] train_loss: -206.72952, val_loss: 130.13219, val_recall@20: 0.12918, val_precision@20: 0.08825, val_ndcg@20: 0.13365\n",
      "[Iteration 7400/10000] train_loss: -212.81636, val_loss: 132.24684, val_recall@20: 0.12922, val_precision@20: 0.08824, val_ndcg@20: 0.13369\n",
      "[Iteration 7600/10000] train_loss: -214.83334, val_loss: 133.97804, val_recall@20: 0.12919, val_precision@20: 0.08822, val_ndcg@20: 0.13366\n",
      "[Iteration 7800/10000] train_loss: -220.11761, val_loss: 135.74448, val_recall@20: 0.12914, val_precision@20: 0.0882, val_ndcg@20: 0.13363\n",
      "[Iteration 8000/10000] train_loss: -206.95453, val_loss: 137.37532, val_recall@20: 0.12926, val_precision@20: 0.08826, val_ndcg@20: 0.13371\n",
      "[Iteration 8200/10000] train_loss: -214.4774, val_loss: 139.03613, val_recall@20: 0.12928, val_precision@20: 0.08827, val_ndcg@20: 0.13372\n",
      "[Iteration 8400/10000] train_loss: -224.49362, val_loss: 140.6721, val_recall@20: 0.12923, val_precision@20: 0.08824, val_ndcg@20: 0.13368\n",
      "[Iteration 8600/10000] train_loss: -222.52235, val_loss: 141.8745, val_recall@20: 0.12923, val_precision@20: 0.08825, val_ndcg@20: 0.1337\n",
      "[Iteration 8800/10000] train_loss: -234.61702, val_loss: 143.55986, val_recall@20: 0.12922, val_precision@20: 0.08826, val_ndcg@20: 0.13372\n",
      "[Iteration 9000/10000] train_loss: -225.71288, val_loss: 144.63431, val_recall@20: 0.12911, val_precision@20: 0.08822, val_ndcg@20: 0.13368\n",
      "[Iteration 9200/10000] train_loss: -228.21632, val_loss: 146.03049, val_recall@20: 0.12922, val_precision@20: 0.08824, val_ndcg@20: 0.13371\n",
      "[Iteration 9400/10000] train_loss: -229.21187, val_loss: 147.67355, val_recall@20: 0.12934, val_precision@20: 0.08829, val_ndcg@20: 0.13377\n",
      "[Iteration 9600/10000] train_loss: -232.29253, val_loss: 148.29567, val_recall@20: 0.12935, val_precision@20: 0.0883, val_ndcg@20: 0.13376\n",
      "[Iteration 9800/10000] train_loss: -236.39505, val_loss: 149.58397, val_recall@20: 0.12931, val_precision@20: 0.08829, val_ndcg@20: 0.13376\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for iter in range(ITERATIONS):\n",
    "    # forward propagation\n",
    "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
    "        train_sparse_edge_index)\n",
    "    # mini batching\n",
    "    user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(\n",
    "        BATCH_SIZE, train_edge_index)\n",
    "    user_indices, pos_item_indices, neg_item_indices = user_indices.to(\n",
    "        device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
    "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
    "    # print(items_emb_final.shape, torch.max(user_indices),\n",
    "            # torch.max(pos_item_indices),torch.max(neg_item_indices),'\\n\\n*************') #####################\n",
    "    # print(items_emb_final,'\\n\\n**********\\n\\n', items_emb_0,'\\n\\n>>>>>', neg_item_indices) ################\n",
    "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
    "        pos_item_indices], items_emb_0[pos_item_indices]\n",
    "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
    "        neg_item_indices], items_emb_0[neg_item_indices]\n",
    "    # print(neg_items_emb_final, neg_items_emb_0) ###########################################\n",
    "\n",
    "    # loss computation\n",
    "    train_loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final,\n",
    "                          pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, LAMBDA)\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if iter % ITERS_PER_EVAL == 0:\n",
    "        model.eval()\n",
    "        val_loss, recall, precision, ndcg = evaluation(\n",
    "            model, val_edge_index, val_sparse_edge_index, [train_edge_index], K, LAMBDA)\n",
    "        print(f\"[Iteration {iter}/{ITERATIONS}] train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\")\n",
    "        train_losses.append(train_loss.item())\n",
    "        val_losses.append(val_loss)\n",
    "        model.train()\n",
    "\n",
    "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'lightgcn_iter10000_b1024.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
